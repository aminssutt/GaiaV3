# ğŸ” Explication complÃ¨te du systÃ¨me FaceID - GAIA

## ğŸ“‹ Vue d'ensemble

Le systÃ¨me FaceID de GAIA permet de **vÃ©rifier l'identitÃ© du conducteur** avant d'accÃ©der au Health Check. Il utilise la **reconnaissance faciale** basÃ©e sur des **landmarks** (points caractÃ©ristiques du visage) dÃ©tectÃ©s par YuNet.

---

## ğŸ› ï¸ Technologies et frameworks utilisÃ©s

### 1. **Backend Python (Serveur DMS)**

#### Framework principal
- **Flask** (`flask`) : Serveur web HTTP pour exposer les endpoints FaceID
- **OpenCV** (`cv2`) : Traitement d'images et dÃ©tection faciale

#### BibliothÃ¨ques de traitement
- **NumPy** (`numpy`) : Calculs mathÃ©matiques sur les embeddings
- **SciPy** (`scipy`) : Fonctions scientifiques (utilisÃ© pour le signal processing DMS)
- **JSON** (built-in) : Stockage persistant des drivers enregistrÃ©s

#### ModÃ¨le de dÃ©tection faciale
- **YuNet** (`face_detection_yunet.onnx`) : ModÃ¨le ONNX pour dÃ©tecter les visages et extraire les landmarks
  - Format : ONNX (Open Neural Network Exchange)
  - Points dÃ©tectÃ©s : 5 landmarks (yeux gauche/droit, nez, bouche gauche/droite)
  - Confiance minimale : 0.6 (60%)

### 2. **Frontend React (GAIA Dashboard)**

#### Services JavaScript
- **FaceIDService** (`src/services/faceIDService.js`) : Client HTTP pour communiquer avec le backend
- **Fetch API** (natif) : RequÃªtes HTTP vers `/faceid/*`

#### Composants React
- **FaceIDVerificationModal** : Modal de vÃ©rification (affiche camÃ©ra + statut)
- **FaceIDEnrollmentModal** : Modal d'enrollment (capture 5 Ã©chantillons)

---

## ğŸ”„ Flux de fonctionnement dÃ©taillÃ©

### **Ã‰TAPE 1 : Enrollment (Enregistrement du conducteur)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Utilisateur clique "Enroll Face ID" dans MainPage      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Frontend appelle: POST /faceid/enroll/start            â”‚
â”‚    â†’ Backend initialise temp_embeddings = []               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Frontend capture 5 Ã©chantillons (toutes les 800ms)    â”‚
â”‚    Pour chaque Ã©chantillon:                               â”‚
â”‚    â†’ POST /faceid/enroll/sample                           â”‚
â”‚    â†’ Backend dÃ©tecte visage dans frame actuel              â”‚
â”‚    â†’ Extrait landmarks (5 points)                          â”‚
â”‚    â†’ Calcule embedding gÃ©omÃ©trique (32 dimensions)        â”‚
â”‚    â†’ Ajoute Ã  temp_embeddings[]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Frontend appelle: POST /faceid/enroll/complete         â”‚
â”‚    â†’ Backend moyenne les 5 embeddings                     â”‚
â”‚    â†’ Normalise le vecteur rÃ©sultant                        â”‚
â”‚    â†’ Sauvegarde dans enrolled_drivers[driver_id]           â”‚
â”‚    â†’ Ã‰crit dans faceid_data.json (persistance)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code clÃ© - Extraction embedding** (`faceid_service.py:57-158`):
```python
def extract_embedding(self, landmarks, bbox, frame_shape):
    """
    CrÃ©e un vecteur de 32 dimensions basÃ© sur:
    1. Positions normalisÃ©es des 5 landmarks (10 valeurs)
    2. Distance inter-yeux
    3. Distances Å“il-nez (2 valeurs)
    4. Largeur de la bouche
    5. Distance nez-bouche
    6. Angle de la ligne des yeux
    7. Position du nez relative aux yeux (2 valeurs)
    8. Position de la bouche relative au nez (2 valeurs)
    9. Ratio d'aspect du visage
    10. Ratio Å“il-nez-bouche
    11. SymÃ©trie faciale
    â†’ Total: 32 dimensions normalisÃ©es
    """
```

**Pourquoi 5 Ã©chantillons ?**
- RÃ©duit le bruit (variations d'Ã©clairage, expressions faciales)
- Moyenne = embedding plus stable et robuste
- Meilleure prÃ©cision lors de la vÃ©rification

---

### **Ã‰TAPE 2 : VÃ©rification (AccÃ¨s Health Check)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Utilisateur clique "Health Check" dans MainPage        â”‚
â”‚    â†’ MainPage vÃ©rifie: isDriverEnrolled(driverId)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Si enrolled â†’ Ouvre FaceIDVerificationModal           â”‚
â”‚    â†’ Affiche flux vidÃ©o (/video_feed)                      â”‚
â”‚    â†’ Auto-dÃ©clenche vÃ©rification aprÃ¨s 1.5s                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Frontend appelle: POST /faceid/verify                   â”‚
â”‚    Body: { "driver_id": "default_driver" }                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Backend (web_dms_server.py:502-529):                   â”‚
â”‚    a) RÃ©cupÃ¨re frame actuel de la camÃ©ra                   â”‚
â”‚    b) DÃ©tecte visage avec YuNet                            â”‚
â”‚    c) Extrait landmarks                                     â”‚
â”‚    d) Appelle faceid_service.verify()                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. faceid_service.verify() (faceid_service.py:237-299):  â”‚
â”‚    a) Extrait embedding du visage actuel                   â”‚
â”‚    b) RÃ©cupÃ¨re embedding enregistrÃ© (driver_id)            â”‚
â”‚    c) Calcule cosine similarity                             â”‚
â”‚    d) Compare avec threshold (0.75 = 75%)                   â”‚
â”‚    e) Retourne:                                            â”‚
â”‚       - verified: True/False                                â”‚
â”‚       - similarity: 0.0-1.0                                 â”‚
â”‚       - driver_id: identifiÃ©                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Frontend reÃ§oit rÃ©sultat                                â”‚
â”‚    â†’ Si verified=True:                                     â”‚
â”‚       â€¢ Affiche "Identity verified!"                        â”‚
â”‚       â€¢ Ferme modal aprÃ¨s 1s                               â”‚
â”‚       â€¢ Navigue vers HealthCheck                            â”‚
â”‚    â†’ Si verified=False:                                    â”‚
â”‚       â€¢ Affiche "Driver not recognized"                     â”‚
â”‚       â€¢ Retry automatique (max 5 tentatives)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code clÃ© - Cosine Similarity** (`faceid_service.py:160-172`):
```python
def cosine_similarity(self, emb1, emb2):
    """
    Mesure la similaritÃ© entre 2 embeddings.
    Retourne une valeur entre -1 et 1:
    - 1.0 = identique
    - 0.0 = orthogonal (diffÃ©rent)
    - -1.0 = opposÃ©
    
    Formule: dot(emb1, emb2) / (||emb1|| * ||emb2||)
    """
    dot = np.dot(emb1, emb2)
    norm1 = np.linalg.norm(emb1)
    norm2 = np.linalg.norm(emb2)
    return dot / (norm1 * norm2)
```

**Seuil de reconnaissance** (`recognition_threshold = 0.75`):
- **â‰¥ 0.75** (75%) â†’ Visage reconnu âœ…
- **< 0.75** â†’ Visage non reconnu âŒ
- Ajustable via `POST /faceid/threshold`

---

## ğŸ“Š Structure des donnÃ©es

### **Embedding (Vecteur de caractÃ©ristiques)**
```python
embedding = np.array([
    # 10 valeurs: positions normalisÃ©es des 5 landmarks
    0.45, 0.32,  # right_eye (x, y)
    0.55, 0.32,  # left_eye
    0.50, 0.45,  # nose
    0.48, 0.58,  # right_mouth
    0.52, 0.58,  # left_mouth
    
    # 22 valeurs: distances, angles, ratios, symÃ©trie...
    0.10,  # inter-eye distance
    0.15, 0.16,  # nose-to-eye distances
    # ... (total 32 dimensions)
], dtype=np.float32)

# NormalisÃ© en vecteur unitaire (norme = 1.0)
embedding = embedding / ||embedding||
```

### **Stockage persistant** (`faceid_data.json`)
```json
{
  "default_driver": [
    0.45, 0.32, 0.55, 0.32, 0.50, 0.45, ...
  ],
  "driver_1": [
    0.42, 0.30, 0.58, 0.30, 0.48, 0.42, ...
  ]
}
```

---

## ğŸ¯ Avantages de cette approche

### âœ… **Avantages**
1. **Pas de deep learning lourd** : Pas besoin de modÃ¨le prÃ©-entraÃ®nÃ© (FaceNet, ArcFace)
2. **LÃ©ger et rapide** : Calculs gÃ©omÃ©triques simples (pas de GPU)
3. **Robuste aux variations** : Normalisation par bbox rÃ©duit l'impact de la distance camÃ©ra
4. **Persistance simple** : JSON suffit (pas de base de donnÃ©es)
5. **Multi-drivers** : Supporte plusieurs conducteurs enregistrÃ©s

### âš ï¸ **Limitations**
1. **Moins prÃ©cis qu'un vrai modÃ¨le deep learning** : Peut confondre des visages similaires
2. **Sensible Ã  l'angle** : Landmarks doivent Ãªtre bien dÃ©tectÃ©s (tÃªte droite recommandÃ©e)
3. **Ã‰clairage** : Variations importantes peuvent affecter la dÃ©tection YuNet
4. **Pas de protection anti-spoofing** : Pas de dÃ©tection de photo/vidÃ©o (mais acceptable pour un usage vÃ©hicule)

---

## ğŸ”§ Configuration et ajustements

### **Seuil de reconnaissance**
```python
# Dans faceid_service.py
self.recognition_threshold = 0.75  # 75%

# Ajuster via API:
POST /faceid/threshold
Body: { "threshold": 0.80 }  # Plus strict (80%)
```

### **Nombre d'Ã©chantillons d'enrollment**
```python
self.enrollment_samples = 5  # Par dÃ©faut

# Plus d'Ã©chantillons = plus robuste mais plus long
```

### **FrÃ©quence de vÃ©rification (DMS)**
```python
# Dans web_dms_server.py (DMSProcessor)
self.faceid_verify_interval = 30  # VÃ©rifie toutes les 30 frames

# Plus frÃ©quent = plus rÃ©actif mais plus de calculs
```

---

## ğŸ§ª Tests locaux

### **Script de test fourni**
```bash
cd cameratest
python test_faceid_local.py
```

Ce script teste:
1. âœ… Service FaceID direct (sans HTTP)
2. âœ… AccÃ¨s camÃ©ra
3. âœ… Endpoints HTTP du serveur

### **Test manuel Ã©tape par Ã©tape**

1. **Lancer le serveur DMS**:
   ```bash
   cd cameratest
   python web_dms_server.py
   ```

2. **Ouvrir GAIA dans le navigateur**:
   ```
   http://localhost:5000
   ```

3. **Enrollment**:
   - MainPage â†’ Profile â†’ Enroll Face ID
   - Regarde la camÃ©ra, bouge lÃ©gÃ¨rement la tÃªte
   - Attends la barre de progression complÃ¨te

4. **VÃ©rification**:
   - MainPage â†’ Health Check
   - Modal FaceID s'ouvre
   - Regarde la camÃ©ra
   - Devrait afficher "Identity verified!"

---

## ğŸ“ RÃ©sumÃ© technique

| Composant | Technologie | RÃ´le |
|-----------|------------|------|
| **DÃ©tection visage** | YuNet (ONNX) | DÃ©tecte visage + extrait 5 landmarks |
| **Extraction features** | GÃ©omÃ©trie pure (NumPy) | CrÃ©e embedding 32D Ã  partir des landmarks |
| **Stockage** | JSON | Persiste les embeddings des drivers |
| **Matching** | Cosine Similarity | Compare embedding actuel vs enregistrÃ© |
| **Seuil** | 0.75 (75%) | DÃ©termine si visage reconnu |
| **Frontend** | React + Fetch API | Interface utilisateur + appels HTTP |
| **Backend** | Flask + OpenCV | Serveur HTTP + traitement images |

---

## ğŸš€ Prochaines amÃ©liorations possibles

1. **Deep Learning** : Remplacer par FaceNet/ArcFace pour meilleure prÃ©cision
2. **Anti-spoofing** : DÃ©tecter photos/vidÃ©os (liveness detection)
3. **Multi-camÃ©ras** : Support plusieurs angles de vue
4. **Temps rÃ©el continu** : VÃ©rification continue pendant la conduite
5. **Base de donnÃ©es** : Remplacer JSON par SQLite/PostgreSQL pour production

---

**Version**: 1.0  
**Date**: Janvier 2025  
**Auteur**: GAIA Development Team
